# Environment Configuration
# Copy this file to .env and fill in your actual values

# LLM Provider Configuration
LLM_PROVIDER=ollama  # Options: openai, ollama, anthropic

# API Keys (only needed for respective providers)
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here
LANGSMITH_API_KEY=your_langsmith_api_key_here

# Ollama Configuration (for local LLM)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=codellama:7b  # Recommended: codellama:7b, llama2:7b, mistral:7b

# Model Configuration
DEFAULT_LLM_MODEL=gpt-4  # Used when LLM_PROVIDER=openai
TEMPERATURE=0.1  # Lower values for more deterministic SQL generation
MAX_TOKENS=1000

# LangSmith Configuration
LANGCHAIN_TRACING_V2=true
LANGCHAIN_PROJECT=ai-database-query-agent
LANGCHAIN_ENDPOINT=https://api.smith.langchain.com

# Database Connections
# PostgreSQL
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=your_database
POSTGRES_USER=your_username
POSTGRES_PASSWORD=your_password

# MySQL
MYSQL_HOST=localhost
MYSQL_PORT=3306
MYSQL_DB=your_database
MYSQL_USER=your_username
MYSQL_PASSWORD=your_password

# MongoDB
MONGODB_URI=mongodb://localhost:27017/your_database

# SQLite
SQLITE_PATH=./data/database.db

# Application Configuration
LOG_LEVEL=INFO
DEBUG=false
MAX_QUERY_TIMEOUT=30
MAX_RESULTS_LIMIT=1000

# Security
SECRET_KEY=your_secret_key_here
ALLOWED_HOSTS=localhost,127.0.0.1

# Rate Limiting
RATE_LIMIT_QUERIES_PER_MINUTE=60
RATE_LIMIT_QUERIES_PER_HOUR=1000

# Query Safety
ALLOW_WRITE_OPERATIONS=false
ALLOW_SCHEMA_CHANGES=false
ENABLE_QUERY_COST_ESTIMATION=true
